# Codex CLI configuration
# Default model, provider and reasoning
model = "gpt-5-codex"
model_provider = "openai-proxy"
model_verbosity = "high"
model_reasoning_effort = "high"

show_raw_agent_reasoning=true

[model_providers.openai-proxy]
name = "OpenAI via Proxy"
base_url = "https://us.imds.ai/openai"
env_key = "OPENAI_API_KEY"
wire_api = "responses"
requires_openai_auth = true

[projects."/Users/home/Downloads/codex"]
trust_level = "trusted"

[projects."/Users/home/Downloads/Claude-Code-Usage-Monitor"]
trust_level = "trusted"

[projects."/Users/home/Downloads/official mcp/mcp-python-sdk"]
trust_level = "trusted"

[projects."/Users/home/Downloads/AI-Guide-and-Demos-zh_CN 2"]
trust_level = "trusted"

[projects."/Users/home/Downloads/mcp"]
trust_level = "trusted"

[projects."/Users/home/Downloads/dartou-ai/gdt"]
trust_level = "trusted"

[projects."/Users/home/Downloads/CpolarAutoUpdater"]
trust_level = "trusted"

[tools]
web_search = true



#[mcp_servers.ad]
#command = "/Users/home/miniforge3/bin/python3"
#args = ["/Users/home/Downloads/mcp/run_server.py"]
#env = { BI_API_TOKEN = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6MTI4LCJ1c2VybmFtZSI6ImppYW5naG91d2FuZyIsInJlYWxfbmFtZSI6Iuaxn-WOmuacmyIsImF2YXRhciI6Imh0dHBzOi8vc3RhdGljLWxlZ2FjeS5kaW5ndGFsay5jb20vbWVkaWEvbFFEUE01WUJVNExTc1JuTkJGYk5CRmF3dlRzajRONEw0QW9JYm9mSzhBUGtBQV8xMTEwXzExMTAuanBnIiwiZGRfdXNlcl9pZCI6IjIyMDUxMjI3MTIyNzM1MDg4MCIsInJvbGVfaWQiOjEsImV4cCI6MTc1Nzk5MTE4NCwiaXNzIjoieGlhby13ZW4tbG9uZyJ9.V5a3iAj7IhlwWx8hmlCiHRaCKlIcqNoaCRyCjLxbx2Q" }

preferred_auth_method = "apikey"
[mcp_servers.serena]
command = "uvx"
args = ["--from", "git+https://github.com/oraios/serena", "serena", "start-mcp-server", "--context", "codex"]
